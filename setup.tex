\section{Experimental Setup}
\paragraph{Compiler and Hardware} We implemented our approach in LLVM 4.0\footnote{Work Profiling: \url{https://github.com/rcorcs/llvm-work-instr}}. Our evaluation platform has a \red{xx-core} 3.4 GHz Intel Core i7 CPU with 16 GB of RAM. The
operating system is \red{Ubuntu 14.02} with Linux kernel 4.4.27.

%The target platform is a Linux-4.4.27 system with an Intel Core i7-4770 3.40GHz Skylake~CPU with 16~GiB RAM.

\paragraph{Benchmarks}
We use the \textit{KDataSets} benchmark suit~\cite{chen10,chen12a}. This suit provides 1,000 different inputs per benchmark. The inputs
have different sizes and often lead to different program execution path. A summary of the benchmarks and their datasets is given in
Table~\ref{tab:kdatasets}. This benchmark suit allows us to evaluate our approach on a large number of inputs provided by independent
developers.

\begin{table*}[t]
\centering
\scriptsize
\scalebox{.8}{
\begin{tabular}{lrlllrlllrll}
\toprule
\textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}   & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.} & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}\\
\midrule
\rowcolor{Gray} bitcount      & 460    &  -                         & Numbers: random                &
dijkstra      & 163    & 0.06K-4.3M                 & Adjacency matrices             &
patricia      & 290    & 0.6K-1.9M                  & IP and mask pairs              \\
mad           & 2358   & 28K-27M                    & MP3 audio      &
ghostscript   & 99869  & 11K-43M                    & Postscript file               &
stringsearch  & 338    &  0.1K-42M                 &  Text files                     \\
\rowcolor{Gray}CRC32         & 130    & 0.6K-35M                   & Files                         &
bzip2e        & 5125   & 0.7K-57M                   & Files                         &
bzip2d        & 5125   & 0.2K-25M                   & Compressed files               \\
\bottomrule
\end{tabular}
}
\caption{Training benchmarks and their inputs}
\label{tab:kdatasets:training}
\end{table*}

\begin{table*}[t]
\centering
\scriptsize
\scalebox{.8}{
\begin{tabular}{lrlllrlllrll}
\toprule
\textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}   & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.} & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}\\
\midrule
\rowcolor{Gray} qsort         & 154    & 32K-1.8M                   & 3D coordinations                     &
jpeg\_d       & 13501  & 3.6K-1.5M                  & JPEG images                    &
jpeg\_c       & 14014  & 16K-137M                   & PPM images                     \\
tiff2bw       & 15477  & 9K-137M                    & TIFF images                    &
tiff2rgba     & 15424  & 9K-137M                    & TIFF images                    &
tiffdither    & 15399  & 9K-137M                    & TIFF images                    \\
\rowcolor{Gray}tiffmedian    & 15870  & 9K-137M                    & TIFF images                    &
susan\_c      & 1376   & 12K-46M                    & PGM images                     &
susan\_e      & 1376   & 12K-46M                    & PGM images                     \\
susan\_s      & 1376   & 12K-46M                    & PGM images                     &
adpcm\_c      & 210    & 167K-36M                   & WAVE audio                    &
adpcm\_d      & 211    & 21K-8.8M                   & ADPCM audio                   \\
\rowcolor{Gray} lame          & 14491  & 167K-36M                   & WAVE audio                    &
rsynth        & 4111   & 0.1K-42M                   &  Text files                    &
sha           & 197    & 0.6K-35M                   & Files of any format            \\
\bottomrule
\end{tabular}
}
\caption{Test benchmarks and their inputs}
\label{tab:kdatasets:test}
\end{table*}

%\begin{table}[h]
%\centering
%\scalebox{.8}{
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Program} & \textbf{LOC}    & \textbf{Input file size}            & \textbf{Input description}              \\ \hline % Domain
%qsort         & 154    & 32K-1.8M                   & 3D coordinates                 \\ \hline
%jpeg\_d       & 13501  & 3.6K-1.5M                  & JPEG images                    \\ \hline
%jpeg\_c       & 14014  & 16K-137M                   & PPM images                     \\ \hline
%tiff2bw       & 15477  & \multirow{4}{*}{9K-137M}   & \multirow{4}{*}{TIFF images}   \\ \cline{1-2}
%tiff2rgba     & 15424  &                            &                                \\ \cline{1-2}
%tiffdither    & 15399  &                            &                                \\ \cline{1-2}
%tiffmedian    & 15870  &                            &                                \\ \hline
%susan\_c      & 1376   & \multirow{3}{*}{12K-46M}   & \multirow{3}{*}{PGM images}    \\ \cline{1-2}
%susan\_e      & 1376   &                            &                                \\ \cline{1-2}
%susan\_s      & 1376   &                            &                                \\ \hline
%adpcm\_c      & 210    & 167K-36M                   & WAVE audios                    \\ \hline
%adpcm\_d      & 211    & 21K-8.8M                   & ADPCM audios                   \\ \hline
%lame          & 14491  & 167K-36M                   & WAVE audios                    \\ \hline
%rsynth        & 4111   & 0.1K-42M                   &  Text files                    \\ \hline
%sha           & 197    & 0.6K-35M                   & Files of any format            \\ \hline
%\rowcolor{gray!20}
%bitcount      & 460    &  -                         & Numbers: random                \\ \hline
%\rowcolor{gray!20}
%dijkstra      & 163    & 0.06K-4.3M                 & Adjacency matrices             \\ \hline
%\rowcolor{gray!20}
%patricia      & 290    & 0.6K-1.9M                  & IP and mask pairs              \\ \hline
%\rowcolor{gray!20}
%mad           & 2358   & 28K-27M                    & MP3 audios                     \\ \hline
%\rowcolor{gray!20}
%%gsm           & 3806   & 83K-18M                    & Sun/NeXT audios                \\ \hline
%ghostscript   & 99869  & 11K-43M                    & Postscript files               \\ \hline
%\rowcolor{gray!20}
%%ispell        & 6522   & \multirow{3}{*}{0.1K-42M}  & \multirow{3}{*}{Text files}    \\ \cline{1-2}
%%rsynth        & 4111   &                            &                                \\ \cline{1-2}
%stringsearch  & 338    &  0.1K-42M                 &  Text files                     \\ \hline
%\rowcolor{gray!20}
%%blowfish\_e   & 863    & 0.6K-35M                   & Files of any format            \\ \hline
%%blowfish\_d   & 863    & 0.6K-35M                   & Encrypted files                \\ \hline
%%pgp\_e        & 19575  & 0.6K-35M                   & Files of any format            \\ \hline
%%pgp\_d        & 19575  & 0.4K-18M                   & Encrypted files                \\ \hline
%%rijndael\_e   & 952    & 0.6K-35M                   & Files of any format            \\ \hline
%%rijndael\_d   & 952    & 0.7K-35M                   & Encrypted files                \\ \hline
%CRC32         & 130    & 0.6K-35M                   & Files of any format            \\ \hline
%\rowcolor{gray!20}
%bzip2e        & 5125   & 0.7K-57M                   & Files of any format            \\ \hline
%\rowcolor{gray!20}
%bzip2d        & 5125   & 0.2K-25M                   & Compressed files               \\ \hline
%\end{tabular}
%}
%\caption{Description of the KDataSets with 1000 inputs for each benchmark (Chen~\etal~\cite{chen10,chen12a}).}
%\label{tab:kdatasets}
%\end{table}


%\begin{table*}[t]
%\centering
%\scriptsize
%\scalebox{.8}{
%\begin{tabular}{lrlllrlllrll}
%\toprule
%\textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}   & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.} & \textbf{Program} & \textbf{LOC}    & \textbf{Input size}            & \textbf{Input desc.}\\          \\
%\midrule
%qsort         & 154    & 32K-1.8M                   & 3D coord.                     &
%jpeg\_d       & 13501  & 3.6K-1.5M                  & JPEG imag.                    &
%jpeg\_c       & 14014  & 16K-137M                   & PPM imag.                     \\
%tiff2bw       & 15477  & 9K-137M                    & TIFF imag.                    &
%tiff2rgba     & 15424  & 9K-137M                    & TIFF imag.                    &
%tiffdither    & 15399  & 9K-137M                    & TIFF imag.                    \\
%tiffmedian    & 15870  & 9K-137M                    & TIFF imag.                    &
%susan\_c      & 1376   & \multirow{3}{*}{12K-46M}   & \multirow{3}{*}{PGM images}    &
%susan\_e      & 1376   &                            &                                \\
%susan\_s      & 1376   &                            &                                &
%adpcm\_c      & 210    & 167K-36M                   & WAVE audios                    &
%adpcm\_d      & 211    & 21K-8.8M                   & ADPCM audios                   \\
%lame          & 14491  & 167K-36M                   & WAVE audios                    &
%rsynth        & 4111   & 0.1K-42M                   &  Text files                    &
%sha           & 197    & 0.6K-35M                   & Files of any format            \\
%bitcount      & 460    &  -                         & Numbers: random                &
%dijkstra      & 163    & 0.06K-4.3M                 & Adjacency matrices             &
%patricia      & 290    & 0.6K-1.9M                  & IP and mask pairs              \\
%mad           & 2358   & 28K-27M                    & MP3 audios                     &
%%gsm           & 3806   & 83K-18M                    & Sun/NeXT audios                \\ \hline
%ghostscript   & 99869  & 11K-43M                    & Postscript files               &
%%ispell        & 6522   & \multirow{3}{*}{0.1K-42M}  & \multirow{3}{*}{Text files}    \\ \cline{1-2}
%%rsynth        & 4111   &                            &                                \\ \cline{1-2}
%stringsearch  & 338    &  0.1K-42M                 &  Text files                     \\
%%blowfish\_e   & 863    & 0.6K-35M                   & Files of any format            \\ \hline
%%blowfish\_d   & 863    & 0.6K-35M                   & Encrypted files                \\ \hline
%%pgp\_e        & 19575  & 0.6K-35M                   & Files of any format            \\ \hline
%%pgp\_d        & 19575  & 0.4K-18M                   & Encrypted files                \\ \hline
%%rijndael\_e   & 952    & 0.6K-35M                   & Files of any format            \\ \hline
%%rijndael\_d   & 952    & 0.7K-35M                   & Encrypted files                \\ \hline
%CRC32         & 130    & 0.6K-35M                   & Files of any format            &
%bzip2e        & 5125   & 0.7K-57M                   & Files of any format            &
%bzip2d        & 5125   & 0.2K-25M                   & Compressed files               \\
%\bottomrule
%\end{tabular}
%}

Table~\ref{tab:kdatasets:training} gives the benchmarks used to train the cost model that is used for computing the instruction weights for
the work metric. These were also used for collecting a fixed set of optimizations for the {\itercomp}. Table~~\ref{tab:kdatasets:test}
lists the testing benchmarks used to evaluate our approach.


\paragraph{Performance Report}
We execute each benchmark with an input a number of times until the gap of the upper and lower confidence bounds is smaller than 5\% under
a 95\% confidence interval setting. We report the geometric mean performance across runs and inputs per benchmark, and provide a min-max
bar to show the variance across inputs.


\paragraph{The Set of Optimization Sequences}
For the purpose of evaluating the use of the WP metric with {\itercomp}, we collected in advance a fixed set of optimization sequences.
The reason for using this fixed set, as explained in Section~\ref{sec:oic-infra}, is because this paper is focused on other components of the infrastructure for performing {\itercomp} and we assume that a good generator of optimization sequences will be used in a real online scenario.
This set contains 500 optimization sequences collected in a random search using the training benchmarks.
These optimization sequences contain an average of 40 individual optimization passes, including repetitions, with a maximum of 119 optimization passes, but it also contains optimization sequences which consist of a single flag, such as the default optimizations {\flagstype -O1}, {\flagstype -O2}, {\flagstype -O3}, {\flagstype -Os}, and {\flagstype -Oz}.

  % \begin{minipage}{0.9\textwidth}
  %    \vspace{1em}
  %    \noindent\textbf{Example of a short optimization sequence:}\vspace{-1ex}
  %    \justify{\flagstype -mem2reg -simplifycfg -constprop -dce}
  % \end{minipage}
  %
  % \begin{minipage}{0.9\textwidth}
  %    \vspace{1em}
  %    \noindent\textbf{Example of a long optimization sequence:}\vspace{-1ex}
  %    \justify{\flagstype -globalopt -reassociate -instcombine -loop-rotate -block-freq -deadargelim -early-cse -sroa -argpromotion -sccp -tbaa -barrier -constmerge \mbox{-loop-vectorize} -domtree -basicaa -memdep -basiccg -memcpyopt \mbox{-constprop} -adce -globaldce -mem2reg -constmerge \mbox{-globaldce} -constprop -instsimplify -dse -dce -simplifycfg -loop-unroll -reassociate -constprop \mbox{-globaldce} -instsimplify -adce -constmerge -bb-vectorize -dce -mergefunc -simplifycfg -dse -loop-unroll -globaldce}
  % \end{minipage}
  %
  % \begin{minipage}{0.9\textwidth}
  %    \vspace{1em}
  %    \noindent\textbf{Example of an optimization sequence which includes {-O3}:}\vspace{-1ex}
  %    \justify{\flagstype -O3 -adce -globaldce -simplifycfg -memcpyopt -reassociate -mergefunc \mbox{-dce} -dse}
  %    \vspace{2em}
  % \end{minipage}

%Repeating the same optimization pass can be beneficial and usually expected by other passes.
%For example, the {\flagstype -loop-simplify} pass is used for transforming loops into a canonical form by inserting pre-header and exit basic blocks.
%Although this pass inserts jumps due to redundant basic blocks, this canonical form can be favourable to other loop optimizations.
%Because of the redundant basic blocks, this optimization pass expects that the {\flagstype -simplifycfg} will eventually be executor later on the optimization pipeline.
%Another example of such inter-relation between transformations concerns the {\flagstype -licm} and {\flagstype -mem2reg} passes.
%The {\flagstype -licm} pass is responsible for moving invariant code out from the loop body.
%It usually creates new local variables, using memory access operations, for assisting with the code manipulation, which means that the executing the {\flagstype -mem2reg} pass afterwards would be useful as a cleanup pass for removing the extra memory accesses generated.
%However, many of the analysis required for identifying loop invariant also benefit from the transformations performed by the {\flagstype -mem2reg} pass.
%These examples illustrate the importance of repeating optimization passes.
%Moreover, they illustrate the intricate relation amongst several transformations.

All optimization sequences in the set of optimizations were generated completely at random, without using any knowledge of individual transformations.
Each optimization sequence was generated in two steps: \textit{(1)} randomly selects the number of flags; \textit{(2)} randomly selects the flags, allowing repetitions.
Afterwards, this randomly generated optimization sequence would be included in the set of optimization sequences only if it was able to improve the performance of a training benchmark, also selected at random, in respect of the {\flagstype -O3} default optimization.
This process was repeated until we obtained all the 500 distinct optimization sequences.
