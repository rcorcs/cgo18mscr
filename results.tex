\section{Experimental Results}\label{sec:results}

%In this section we discuss our experimental evaluation. Afterwards, we discuss our results concerning the instrumentations for profiling
%our work metric. Finally we present the results of the online {\itercomp}.

In this section we discuss our experimental evaluation of the work profiling strategies and
the effectiveness of the work efficiency metric on guiding true online {\itercomp}.
We use the following naming convension for the profiling strategies considered
throughout this section:
\begin{itemize}[leftmargin=3mm]
\item \textbf{\OracleRM} measures the actual speedup over the unoptimized version of the program for any given input.
In our experiments, this oracle is allowed to execute each input at least twice so the speedup can be computed.
\item \textbf{\OraclePP} measures the work efficiency metric with a \textit{magically perfect} non-intrusive profiling.
  Because this version simulates a \textit{perfect} profiling, with zero overhead,
  it allows us to isolate and evaluate the actual effectiveness of the work efficiency metric.
\item \textbf{\OptProf} corresponds to the work profiling using the optimal placement of the probes.
  This profiling strategy requires a single execution of the program for any given input.
\item \textbf{\WCRelax-\textit{N}\%} measures the work efficiency metric using the work profiling with a \textit{N}\% thresheld for
the \WCRelaxLower relaxation.
  Similar to the \OptProf, this profiling strategy also requires a single execution of the program for any given input.
\item \textbf{\WPRelax-\textit{N}\%} is similar to the \WCRelax, but it applies the \WPRelaxLower relaxation instead.
\end{itemize}

\subsection{Evaluation of the Instrumentation}

In this experiment we evaluate the runtime overhead introduced by the work efficiency profiling. We compile the program using the
\texttt{-O3}. We then measure the wall-clock time of the instrumented and the native versions to calculate the runtime overhead. For
each benchmark, we compute the average overhead over all its 1,000 inputs.
Figure~\ref{fig:overhead-O3} shows the runtime overhead imposed by the work profiling using each of the proposed work profiling strategies over
their non-instrumented counterparts.
%The WPO relaxation was performed using profiling information for every specific input, which provides
%the perfect information to perform the WPO relaxation. This means that the experiments show its best performance enabled by having perfect
%profiling information.

%\begin{figure}[t]
%    \centering
%    \includegraphics[width=0.395\textwidth]{figs/adpcm_d-cfg-instr.pdf}
%    \caption{CFG of the function that contains the hot loop of the {\flagstype adpcm\_d} benchmark.}
%    \label{fig:adpcm_d-cfg-instr}
%\end{figure}

While the \OptProf has a maximum overhead of near 60\%, the \WCRelax-\textit{5}\% has an overhead of
less than 16\% for all benchmarks, with the \WPRelax-\textit{5}\% reaches an average overhead of only 5\%,
compared to an average overhead of 12\% for the optimal profiling.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figs/overhead-O3.pdf}
    \caption{Overhead of the instrumentations compiled with {\flagstype -O3}.}
    \label{fig:overhead-O3}
\end{figure*}
\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figs/error-O3.pdf}
    \caption{Dynamic error of the work profiling averaged over the 1000 inputs, after relaxing the number of probes.}
    \label{fig:error-O3}
\end{figure*}

%Mean values...
%Real-R5: 30.43\%
%WPO-R5:  54.97\%
%adpcm_d:
%Real-R5: 75.51\%
%WPO-R5:  79.07\%

The most critical case, amongst the evaluated benchmarks, happens with the
\texttt{adpcm\_d} program, with an overhead of about 59\% for the optimal
instrumentation.
With a threshold of only 5\%, the \WCRelaxLower relaxation reduces
the overhead by about 75\% over the \OptProf,
and the \WPRelax-5\% reduces it by about 80\%.
This benchmark has a single hot function
which consists mainly of a single hot loop with several branches inside it. %, as depicted by Figure~\ref{fig:adpcm_d-cfg-instr}.
Most of the improvement achieved by both strategies comes from removing only two probes from the hot loop. The two relaxed probes were
placed in branches with a high probability of being taken, but with a small contribution to the total amount of
work measured in DAG for this loop (both probes with an static error of about 1.3\%). Because these probes were placed in basic blocks with
a considerable execution frequency, removing the probes resulted in a significant reduction in runtime overhead.

A few of the benchmarks present abnormal regressions in their execution time.
This increase in the profiling overhead is counter-intuitive because the
relaxation algorithms only reduces the number of instrumented probes,
without changing their placement.
We suggest some reasons for these abnormal regressions.
By analyzing these cases, we noticed that some of the frequently executed
probes could not be removed by the relaxation strategies with small thresholds.
Another important aspect to point out is that we also observed
differences among the final CFGs after applying the \texttt{-O3} optimization.
Although relaxation does not directly alter the CFG, it is worth mentioning that
there are optimizations that make use of LLVM's built-in target-based cost model,
which means that adding or removing instructions from basic blocks may affect
decisions during transformations of the code, which may end up changing the CFG
in different ways depending on the instrumentation applied.
%For example, some of the optimizations that make use of this built-in cost model
%and also alter the CFG are: loop-unrolling, function inlining, and
%simplifications of the CFG.
%These changes in the program's CFGs may affect other compiler optimizations and
%also possibly in hardware performance, for example affecting the instruction
%caching.

Finally, as shown in Figure~\ref{fig:error-O3}, these improvements can be
obtained while incurring very little dynamic error.
This result confirms the overly conservative aspect of the \WCRelaxLower relaxation,
while the \WPRelaxLower relaxation is significantly less conservative.
Although the error bound is not guaranteed by the \WPRelaxLower relaxation,
its dynamic error was always below the 5\% thresholds.
%due to the use of perfect profiling information.

\subsection{Evaluation of Online {\IterComp}}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figs/speedups.pdf}
    \caption{Speedups obtained from the final optimization sequence selected by the online {\itercomp}.
	         The speedups reported for each benchmark represents the average speedup across their complete 1000 input datasets.}
    \label{fig:speedups}
\end{figure*}

In this section we evaluate the effectiveness of our work efficiency metric.
We perform online {\itercomp} using all five profiling strategies, namely
\OracleRM, \OraclePP,\OptProf,\WCRelax-5\%, and \WPRelax-5\%.
Because the \OracleRM measures actual speedup, it provides reference results for
assessing the effectiveness of the work-efficiency metric.
For the relaxation strategies, we evaluate only those with a 5\% threshold, since
they offered better overhead reductions for little dynamic errors in the measurement.

For all strategies, the same optimization sequence is used for multiple inputs, using a dynamic input-window size, as explained in
Section~\ref{sec:oic-infra}. The average performance over the input window provides an estimate for the overall performance of the
optimization sequence across distinct inputs. The optimization sequences are ranked based on their average performance, and the best
optimization sequence is selected.

The comparison between \OracleRM and \OraclePP is crucial for validating the
effectiveness of the work efficiency metric in guiding online {\itercomp},
while the other configurations demonstrate the viability of applying online
{\itercomp} in real-world scenarios.

In order to evaluate the quality of the final optimization sequences selected by each configuration of the online {\itercomp}, we compare
their speedup over the \texttt{-O3} optimization across all the 1,000 inputs of the benchmark being optimized. None of the configurations
degrades the performance over \texttt{-O3} (with statistical significance).
%When measuring the wall-clock time for each input, to reduce noise, we execute
%the same input until we have a statistically sound measurement, i.e. we execute
%until we have an interval no larger than 1\% with 99\% confidence.
Figure~\ref{fig:speedups} shows these average speedups for all test benchmarks.
This figure shows that the best optimization sequence selected with the Oracle-PP
is very close to the performance of the best optimization sequence selected with
the \OracleRM, where \OraclePP achieves on average about 80\% of the performance
improvement obtained by the \OracleRM.
This result is important for demonstrating that our work efficiency metric has
the potential to produce good results in real-world online scenarios.

The \OptProf achieves 4\% improvement on average, which represents 45\% of the
performance improvement obtained by the \OracleRM.
This difference to \OraclePP is explained by the real (intrusive) profiling used
in the \OptProf configuration.
The profiling affects the search in two key ways:
\textit{(i.)} the overhead incurred by the profiling affects the execution time,
and therefore also affects the work efficiency metric,
\textit{(ii.)} the instrumentation code may affect many of the optimizations, e.g.,
due to the use of a global variable or in decisions taken based on a cost-model
for the instructions.
However, even in the \OptProf configuration, which has a highly intrusive instrumentation,
it is still possible to obtain performance improvements in a realistic online
{\itercomp}.

Finally, the evaluation also indicates that the use of relaxation algorithms
is beneficial not only for its reduction in overhead, which is directly observed
by the user, by it also tends to improve the quality of the search.
This improvement has to do with the aforementioned effects of an intrusive
instrumentation on the search.
The relaxation has the potential to reduce both effects of the profiling.
Both the \WCRelax-5\% and \WPRelax-5\% achieve about 60\% of the
performance improvement obtained by the \OracleRM.
